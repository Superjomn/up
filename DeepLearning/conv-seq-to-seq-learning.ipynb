{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv Sequence to Sequence Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "- <span class=\"mark\">CONV's output elements equals input</span>\n",
    "    - set the kernel size to $k$\n",
    "    - pad $k/2$ in both left and right sides\n",
    "    - delete the last $k/2$ elements from output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Embeddings\n",
    "- the input tokens $x=(x_1, \\cdots, x_m)$\n",
    "    - the corresponding word vectors $w=(w_1, \\cdots, w_m)$\n",
    "- position embeddings to give CNN a sense of the portioin of the sequence is currently dealing with\n",
    "    - $p=(p_1, \\cdots, p_m)$\n",
    "- the input elements are represented as\n",
    "    - $e=(w_1+p_1,\\cdots,w_m+p_m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Block Structure\n",
    "\n",
    "- each block contains **a** one dimensional convolution followed by a non-linearity\n",
    "- stacking several blocks on top of each other increases the number of input elements represented in a state\n",
    "    - just like a pyramid, only in that way Conv can learn a single or several states from a long but fixed-length sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*it seems that each level-$l$ will has $k-l$ outputs, so stacking 5 kernel-5-blocks will result in a single one output*\n",
    "\n",
    "So if we have 25 inputs, with another stack can transform these 25 inputs to a single state.\n",
    "```\n",
    "|\n",
    "||\n",
    "|||\n",
    "||||\n",
    "|||||\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLU (gated linear unit)\n",
    "- add non-linearities to allow the networks to exploit the full input field, or the focus on fewer elements if needed\n",
    "- each convolution kernel is parameterized as $W\\in R^{2d\\times kd}$\n",
    "    - $d$ the embedding dimension\n",
    "    - $k$ the kernel size\n",
    "    - so the output of each kernel is $2d$, twice of the input dimension\n",
    "- GLU is performed on the $2d$ output as simple gated nonlinearities.\n",
    "\n",
    "\\begin{equation}\n",
    "v([A,B]) = A \\otimes\\sigma(B)\n",
    "\\end{equation}\n",
    "\n",
    "- $\\sigma(B)$ is a gate\n",
    "- $A$ and $B$ are concated as the 2d output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### residual connections to enable deep convolutional networks\n",
    "\n",
    "\\begin{equation}\n",
    "h_i^l = v(W^l [h^{l-1}_{i-k/2},\\cdots,h^{l-1}_{i+k/2}]+b^l_w)\n",
    "+h^{l-1}_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding strategory\n",
    "- pad the input by $k-1$ elements on both the left and right sides by zero vectors\n",
    "- remote $k$ elements from the end of the convolution output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-step Attention\n",
    "\n",
    "- separate attention mechanism for each decoder layer\n",
    "- combine the current decoder state $h^l_i$ with an embedding of the previous target element $g_i$\n",
    "\n",
    "\\begin{equation}\n",
    "d^l_i = W^l_d h^l_i + b^l_d + g_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each layer has seperate attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a^l_{ij} = \\frac{exp \\left(d^l_i . z^u_j\\right)}\n",
    "{\\sum_{t=1}^m exp\\left(d^l_i. z_t^u\\right)}\n",
    "$$\n",
    "\n",
    "The conditional input $c_i^l$ to the current decoder layer is a weighted sum of the **encoder outputs** as well as the **input element embeddings** $e_i$\n",
    "\n",
    "$$\n",
    "c^l_i=\\sum_{j=1}^m a^l_{ij}\\left( z_j^u+e_j\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple decoder CONV layers to learn a sequence, for each decoder layer, a attention layer is used to calculate a context vector just for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
